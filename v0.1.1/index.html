<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · CSV.jl documentation</title><link href="assets/documenter.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><link rel="canonical" href="https://juliadata.github.io/CSV.jl/stable/index.html"/><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script></head><body><nav class="toc"><h1>CSV.jl</h1><form class="search" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href="index.html">Home</a><ul class="internal"><li><a class="toctext" href="#High-level-interface-1">High-level interface</a></li><li><a class="toctext" href="#Lower-level-utilities-1">Lower-level utilities</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href="index.html">Home</a></li></ul><a class="edit-page" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h1><a class="nav-anchor" id="CSV.jl-Documentation-1" href="#CSV.jl-Documentation-1">CSV.jl Documentation</a></h1><p>CSV.jl is built to be a fast and flexible pure-Julia library for handling delimited text files.</p><ul><li><a href="index.html#CSV.jl-Documentation-1">CSV.jl Documentation</a></li><ul><li><a href="index.html#High-level-interface-1">High-level interface</a></li><li><a href="index.html#Lower-level-utilities-1">Lower-level utilities</a></li></ul></ul><h2><a class="nav-anchor" id="High-level-interface-1" href="#High-level-interface-1">High-level interface</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.read" href="#CSV.read"><code>CSV.read</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.read(fullpath::Union{AbstractString,IO}, sink::Type{T}=DataFrame, args...; kwargs...)</code> =&gt; <code>typeof(sink)</code> <code>CSV.read(fullpath::Union{AbstractString,IO}, sink::Data.Sink; kwargs...)</code> =&gt; <code>Data.Sink</code></p><p>parses a delimited file into a Julia structure (a DataFrame by default, but any valid <code>Data.Sink</code> may be requested).</p><p>Positional arguments:</p><ul><li><p><code>fullpath</code>; can be a file name (string) or other <code>IO</code> instance</p></li><li><p><code>sink::Type{T}</code>; <code>DataFrame</code> by default, but may also be other <code>Data.Sink</code> types that support streaming via <code>Data.Field</code> interface; note that the method argument can be the <em>type</em> of <code>Data.Sink</code>, plus any required arguments the sink may need (<code>args...</code>).                   or an already constructed <code>sink</code> may be passed (2nd method above)</p></li></ul><p>Keyword Arguments:</p><ul><li><p><code>delim::Union{Char,UInt8}</code>; a single character or ascii-compatible byte that indicates how fields in the file are delimited; default is <code>UInt8(&#39;,&#39;)</code></p></li><li><p><code>quotechar::Union{Char,UInt8}</code>; the character that indicates a quoted field that may contain the <code>delim</code> or newlines; default is <code>UInt8(&#39;&quot;&#39;)</code></p></li><li><p><code>escapechar::Union{Char,UInt8}</code>; the character that escapes a <code>quotechar</code> in a quoted field; default is <code>UInt8(&#39;\&#39;)</code></p></li><li><p><code>null::String</code>; an ascii string that indicates how NULL values are represented in the dataset; default is the empty string, <code>&quot;&quot;</code></p></li><li><p><code>header</code>; column names can be provided manually as a complete Vector{String}, or as an Int/Range which indicates the row/rows that contain the column names</p></li><li><p><code>datarow::Int</code>; specifies the row on which the actual data starts in the file; by default, the data is expected on the next row after the header row(s); for a file without column names (header), specify <code>datarow=1</code></p></li><li><p><code>types</code>; column types can be provided manually as a complete Vector{DataType}, or in a Dict to reference individual columns by name or number</p></li><li><p><code>nullable::Bool</code>; indicates whether values can be nullable or not; <code>true</code> by default. If set to <code>false</code> and missing values are encountered, a <code>NullException</code> will be thrown</p></li><li><p><code>dateformat::Union{AbstractString,Dates.DateFormat}</code>; how all dates/datetimes in the dataset are formatted</p></li><li><p><code>footerskip::Int</code>; indicates the number of rows to skip at the end of the file</p></li><li><p><code>rows_for_type_detect::Int=100</code>; indicates how many rows should be read to infer the types of columns</p></li><li><p><code>rows::Int</code>; indicates the total number of rows to read from the file; by default the file is pre-parsed to count the # of rows; <code>-1</code> can be passed to skip a full-file scan, but the <code>Data.Sink</code> must be setup account for a potentially unknown # of rows</p></li><li><p><code>use_mmap::Bool=true</code>; whether the underlying file will be mmapped or not while parsing</p></li><li><p><code>append::Bool=false</code>; if the <code>sink</code> argument provided is an existing table, <code>append=true</code> will append the source&#39;s data to the existing data instead of doing a full replace</p></li><li><p><code>transforms::Dict{Union{String,Int},Function}</code>; a Dict of transforms to apply to values as they are parsed. Note that a column can be specified by either number or column name.</p></li></ul><p>Note by default, &quot;string&quot; or text columns will be parsed as the <a href="https://github.com/quinnj/WeakRefStrings.jl"><code>WeakRefString</code></a> type. This is a custom type that only stores a pointer to the actual byte data + the number of bytes. To convert a <code>String</code> to a standard Julia string type, just call <code>string(::WeakRefString)</code>, this also works on an entire column. Oftentimes, however, it can be convenient to work with <code>WeakRefStrings</code> depending on the ultimate use, such as transfering the data directly to another system and avoiding all the intermediate copying.</p><p>Example usage:</p><pre><code class="language-none">julia&gt; dt = CSV.read(&quot;bids.csv&quot;)
7656334×9 DataFrames.DataFrame
│ Row     │ bid_id  │ bidder_id                               │ auction │ merchandise      │ device      │
├─────────┼─────────┼─────────────────────────────────────────┼─────────┼──────────────────┼─────────────┤
│ 1       │ 0       │ &quot;8dac2b259fd1c6d1120e519fb1ac14fbqvax8&quot; │ &quot;ewmzr&quot; │ &quot;jewelry&quot;        │ &quot;phone0&quot;    │
│ 2       │ 1       │ &quot;668d393e858e8126275433046bbd35c6tywop&quot; │ &quot;aeqok&quot; │ &quot;furniture&quot;      │ &quot;phone1&quot;    │
│ 3       │ 2       │ &quot;aa5f360084278b35d746fa6af3a7a1a5ra3xe&quot; │ &quot;wa00e&quot; │ &quot;home goods&quot;     │ &quot;phone2&quot;    │
...</code></pre><p>Other example invocations may include:</p><pre><code class="language-julia"># read in a tab-delimited file
CSV.read(file; delim=&#39;	&#39;)

# read in a comma-delimited file with null values represented as &#39;N&#39;, such as a MySQL export
CSV.read(file; null=&quot;\N&quot;)

# manually provided column names; must match # of columns of data in file
# this assumes there is no header row in the file itself, so data parsing will start at the very beginning of the file
CSV.read(file; header=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;])

# manually provided column names, even though the file itself has column names on the first row
# `datarow` is specified to ensure data parsing occurs at correct location
CSV.read(file; header=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;], datarow=2)

# types provided manually; as a vector, must match length of columns in actual data
CSV.read(file; types=[Int, Int, Float64])

# types provided manually; as a Dict, can specify columns by # or column name
CSV.read(file; types=Dict(3=&gt;Float64, 6=&gt;String))
CSV.read(file; types=Dict(&quot;col3&quot;=&gt;Float64, &quot;col6&quot;=&gt;String))

# manually provided # of rows; if known beforehand, this will improve parsing speed
# this is also a way to limit the # of rows to be read in a file if only a sample is needed
CSV.read(file; rows=10000)

# for data files, `file` and `file2`, with the same structure, read both into a single DataFrame
# note that `df` is used as a 2nd argument in the 2nd call to `CSV.read` and the keyword argument
# `append=true` is passed
df = CSV.read(file)
df = CSV.read(file2, df; append=true)

# manually construct a `CSV.Source` once, then stream its data to both a DataFrame
# and SQLite table `sqlite_table` in the SQLite database `db`
# note the use of `CSV.reset!` to ensure the `source` can be streamed from again
source = CSV.Source(file)
df1 = CSV.read(source, DataFrame)
CSV.reset!(source)
db = SQLite.DB()
sq1 = CSV.read(source, SQLite.Sink, db, &quot;sqlite_table&quot;)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/Source.jl#L189-L277">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.write" href="#CSV.write"><code>CSV.write</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.write(file_or_io::Union{AbstractString,IO}, source::Type{T}, args...; kwargs...)</code> =&gt; <code>CSV.Sink</code> <code>CSV.write(file_or_io::Union{AbstractString,IO}, source::Data.Source; kwargs...)</code> =&gt; <code>CSV.Sink</code></p><p>write a <code>Data.Source</code> out to a <code>file_or_io</code>.</p><p>Positional Arguments:</p><ul><li><p><code>file_or_io</code>; can be a file name (string) or other <code>IO</code> instance</p></li><li><p><code>source</code> can be the <em>type</em> of <code>Data.Source</code>, plus any required <code>args...</code>, or an already constructed <code>Data.Source</code> can be passsed in directly (2nd method)</p></li></ul><p>Keyword Arguments:</p><ul><li><p><code>delim::Union{Char,UInt8}</code>; how fields in the file will be delimited; default is <code>UInt8(&#39;,&#39;)</code></p></li><li><p><code>quotechar::Union{Char,UInt8}</code>; the character that indicates a quoted field that may contain the <code>delim</code> or newlines; default is <code>UInt8(&#39;&quot;&#39;)</code></p></li><li><p><code>escapechar::Union{Char,UInt8}</code>; the character that escapes a <code>quotechar</code> in a quoted field; default is <code>UInt8(&#39;\&#39;)</code></p></li><li><p><code>null::String</code>; the ascii string that indicates how NULL values will be represented in the dataset; default is the emtpy string <code>&quot;&quot;</code></p></li><li><p><code>dateformat</code>; how dates/datetimes will be represented in the dataset; default is ISO-8601 <code>yyyy-mm-ddTHH:MM:SS.s</code></p></li><li><p><code>header::Bool</code>; whether to write out the column names from <code>source</code></p></li><li><p><code>colnames::Vector{String}</code>; a vector of string column names to be used when writing the header row</p></li><li><p><code>append::Bool</code>; start writing data at the end of <code>io</code>; by default, <code>io</code> will be reset to the beginning or overwritten before writing</p></li><li><p><code>transforms::Dict{Union{String,Int},Function}</code>; a Dict of transforms to apply to values as they are parsed. Note that a column can be specified by either number or column name.</p></li></ul><p>A few example invocations include:</p><pre><code class="language-julia"># write out a DataFrame `df` to a file name &quot;out.csv&quot; with all defaults, including comma as delimiter
CSV.write(&quot;out.csv&quot;, df)

# write out a DataFrame, this time as a tab-delimited file
CSV.write(&quot;out.csv&quot;, df; delim=&#39;	&#39;)

# write out a DataFrame, with null values represented by the string &quot;NA&quot;
CSV.write(&quot;out.csv&quot;, df; null=&quot;NA&quot;)

# write out a &quot;header-less&quot; file, with actual data starting on row 1
CSV.write(&quot;out.csv&quot;, df; header=false)

# write out a DataFrame `df` twice to a file, the resulting file with have twice the # of rows as the DataFrame
# note the usage of the keyword argument `append=true` in the 2nd call
CSV.write(&quot;out.csv&quot;, df)
CSV.write(&quot;out.csv&quot;, df; append=true)

# write a DataFrame out to an IOBuffer instead of a file
io = IOBuffer
CSV.write(io, df)

# write the result of an SQLite query out to a comma-delimited file
db = SQLite.DB()
sqlite_source = SQLite.Source(db, &quot;select * from sqlite_table&quot;)
CSV.write(&quot;sqlite_table.csv&quot;, sqlite_source)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/Sink.jl#L78-L129">source</a><br/></section><h2><a class="nav-anchor" id="Lower-level-utilities-1" href="#Lower-level-utilities-1">Lower-level utilities</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.Source" href="#CSV.Source"><code>CSV.Source</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A type that satisfies the <code>Data.Source</code> interface in the <code>DataStreams.jl</code> package.</p><p>A <code>CSV.Source</code> can be manually constructed in order to be re-used multiple times.</p><p><code>CSV.Source(file_or_io; kwargs...) =&gt; CSV.Source</code></p><p>Note that a filename string can be provided or any <code>IO</code> type. For the full list of supported keyword arguments, see the docs for <a href="index.html#CSV.read"><code>CSV.read</code></a> or type <code>?CSV.read</code> at the repl</p><p>An example of re-using a <code>CSV.Source</code> is:</p><pre><code class="language-julia"># manually construct a `CSV.Source` once, then stream its data to both a DataFrame
# and SQLite table `sqlite_table` in the SQLite database `db`
# note the use of `CSV.reset!` to ensure the `source` can be streamed from again
source = CSV.Source(file)
df1 = CSV.read(source, DataFrame)
CSV.reset!(source)
sq1 = CSV.read(source, SQLite.Sink, db, &quot;sqlite_table&quot;)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/CSV.jl#L78-L98">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.Sink" href="#CSV.Sink"><code>CSV.Sink</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A type that satisfies the <code>Data.Sink</code> interface in the <code>DataStreams.jl</code> package.</p><p>A <code>CSV.Sink</code> can be manually constructed in order to be re-used multiple times.</p><p><code>CSV.Sink(file_or_io; kwargs...) =&gt; CSV.Sink</code></p><p>Note that a filename string can be provided or any <code>IO</code> type. For the full list of supported keyword arguments, see the docs for <a href="index.html#CSV.write"><code>CSV.write</code></a> or type <code>?CSV.write</code> at the repl</p><p>An example of re-using a <code>CSV.Sink</code> is:</p><pre><code class="language-julia"># manually construct a `CSV.Source` once, then stream its data to both a DataFrame
# and SQLite table `sqlite_table` in the SQLite database `db`
# note the use of `CSV.reset!` to ensure the `source` can be streamed from again
source = CSV.Source(file)
df1 = CSV.read(source, DataFrame)
CSV.reset!(source)
sq1 = CSV.read(source, SQLite.Sink, db, &quot;sqlite_table&quot;)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/CSV.jl#L114-L134">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.Options" href="#CSV.Options"><code>CSV.Options</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Represents the various configuration settings for delimited text file parsing.</p><p>Keyword Arguments:</p><ul><li><p><code>delim::Union{Char,UInt8}</code>; how fields in the file are delimited</p></li><li><p><code>quotechar::Union{Char,UInt8}</code>; the character that indicates a quoted field that may contain the <code>delim</code> or newlines</p></li><li><p><code>escapechar::Union{Char,UInt8}</code>; the character that escapes a <code>quotechar</code> in a quoted field</p></li><li><p><code>null::String</code>; indicates how NULL values are represented in the dataset</p></li><li><p><code>dateformat::Union{AbstractString,Dates.DateFormat}</code>; how dates/datetimes are represented in the dataset</p></li></ul></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/CSV.jl#L40-L50">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.parsefield" href="#CSV.parsefield"><code>CSV.parsefield</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.parsefield{T}(io::IO, ::Type{T}, opt::CSV.Options=CSV.Options(), row=0, col=0)</code> =&gt; <code>Nullable{T}</code> <code>CSV.parsefield{T}(s::CSV.Source, ::Type{T}, row=0, col=0)</code> =&gt; <code>Nullable{T}</code>`</p><p><code>io</code> is an <code>IO</code> type that is positioned at the first byte/character of an delimited-file field (i.e. a single cell) leading whitespace is ignored for Integer and Float types. returns a <code>Nullable{T}</code> saying whether the field contains a null value or not (empty field, missing value) field is null if the next delimiter or newline is encountered before any other characters. Specialized methods exist for Integer, Float, String, Date, and DateTime. For other types <code>T</code>, a generic fallback requires <code>parse(T, str::String)</code> to be defined. the field value may also be wrapped in <code>opt.quotechar</code>; two consecutive <code>opt.quotechar</code> results in a null field <code>opt.null</code> is also checked if there is a custom value provided (i.e. &quot;NA&quot;, &quot;\N&quot;, etc.) For numeric fields, if field is non-null and non-digit characters are encountered at any point before a delimiter or newline, an error is thrown</p><p>The second method of <code>CSV.parsefield</code> operates on a <code>CSV.Source</code> directly allowing for easy usage when writing custom parsing routines. Do note, however, that the <code>row</code> and <code>col</code> arguments are for error-reporting purposes only. A <code>CSV.Source</code> maintains internal state with regards to the underlying data buffer and can <strong>only</strong> parse fields sequentially. This means that <code>CSV.parsefield</code> needs to be called somewhat like:</p><pre><code class="language-julia">source = CSV.Source(file)

types = Data.types(source)

for col = 1:length(types)
    println(get(CSV.parsefield(source, types[col]), &quot;&quot;&quot;&quot;))
end</code></pre></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/parsefields.jl#L72-L99">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.readline" href="#CSV.readline"><code>CSV.readline</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.readline(io::IO, q=&#39;&quot;&#39;, e=&#39;\&#39;, buf::IOBuffer=IOBuffer())</code> =&gt; <code>String</code> <code>CSV.readline(source::CSV.Source)</code> =&gt; <code>String</code></p><p>read a single line from <code>io</code> (any <code>IO</code> type) or a <code>CSV.Source</code> as a string, accounting for potentially embedded newlines in quoted fields (e.g. value1, value2, &quot;value3 with   embedded newlines&quot;). Can optionally provide a <code>buf::IOBuffer</code> type for buffer reuse</p><p>This function basically mirrors <code>Base.readline</code> except it can account for quoted newlines to <strong>not</strong> as the true end of a line.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/io.jl#L1-L12">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.readsplitline" href="#CSV.readsplitline"><code>CSV.readsplitline</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.readsplitline(io, d=&#39;,&#39;, q=&#39;&quot;&#39;, e=&#39;\&#39;, buf::IOBuffer=IOBuffer())</code> =&gt; <code>Vector{String}</code> <code>CSV.readsplitline(source::CSV.Source)</code> =&gt; <code>Vector{String}</code></p><p>read a single, delimited line from <code>io</code> (any <code>IO</code> type) or a <code>CSV.Source</code> as a <code>Vector{String}</code> delimited fields are separated by an ascii character <code>d</code>). Can optionally provide a <code>buf::IOBuffer</code> type for buffer reuse</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/io.jl#L41-L48">source</a><br/></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.countlines" href="#CSV.countlines"><code>CSV.countlines</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>CSV.countlines(io::IO, quotechar, escapechar)</code> =&gt; <code>Int</code> <code>CSV.countlines(source::CSV.Source)</code> =&gt; <code>Int</code></p><p>count the number of lines in a file, accounting for potentially embedded newlines in quoted fields</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/tree/e08c50da9c28458f8341fb9e9bc749e4aee46255/src/io.jl#L84-L89">source</a><br/></section><footer><hr/></footer></article></body></html>
