<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>CSV.jl Documentation · CSV.jl</title><link rel="canonical" href="https://juliadata.github.io/CSV.jl/stable/index.html"/><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CSV.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li class="current"><a class="toctext" href>CSV.jl Documentation</a><ul class="internal"><li><a class="toctext" href="#Getting-Started-1">Getting Started</a></li><li><a class="toctext" href="#Key-Functions-1">Key Functions</a></li><li><a class="toctext" href="#Examples-1">Examples</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>CSV.jl Documentation</a></li></ul><a class="edit-page" href="https://github.com/JuliaData/CSV.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>CSV.jl Documentation</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="CSV.jl-Documentation-1" href="#CSV.jl-Documentation-1">CSV.jl Documentation</a></h1><p>CSV.jl is built to be a fast and flexible pure-Julia library for handling delimited text files.</p><ul><li><a href="#CSV.jl-Documentation-1">CSV.jl Documentation</a></li><ul><li><a href="#Getting-Started-1">Getting Started</a></li><li><a href="#Key-Functions-1">Key Functions</a></li><li><a href="#Examples-1">Examples</a></li><ul><li><a href="#Basic-1">Basic</a></li><li><a href="#Auto-Delimiter-Detection-1">Auto-Delimiter Detection</a></li><li><a href="#String-Delimiter-1">String Delimiter</a></li><li><a href="#No-Header-1">No Header</a></li><li><a href="#Normalize-Column-Names-1">Normalize Column Names</a></li><li><a href="#Datarow-1">Datarow</a></li><li><a href="#Reading-Chunks-1">Reading Chunks</a></li><li><a href="#Transposed-Data-1">Transposed Data</a></li><li><a href="#Commented-Rows-1">Commented Rows</a></li><li><a href="#Missing-Strings-1">Missing Strings</a></li><li><a href="#Fixed-Width-Files-1">Fixed Width Files</a></li><li><a href="#Quoted-and-Escaped-Fields-1">Quoted &amp; Escaped Fields</a></li><li><a href="#DateFormat-1">DateFormat</a></li><li><a href="#Custom-Decimal-Separator-1">Custom Decimal Separator</a></li><li><a href="#Custom-Bool-Strings-1">Custom Bool Strings</a></li><li><a href="#Matrix-like-Data-1">Matrix-like Data</a></li><li><a href="#Providing-Types-1">Providing Types</a></li><li><a href="#Typemap-1">Typemap</a></li><li><a href="#Pooled-Values-1">Pooled Values</a></li><li><a href="#Select/Drop-Columns-From-File-1">Select/Drop Columns From File</a></li><li><a href="#Non-UTF-8-character-encodings-1">Non-UTF-8 character encodings</a></li><li><a href="#Reading-CSV-from-gzip-(.gz)-and-zip-files-1">Reading CSV from gzip (.gz) and zip files</a></li></ul></ul></ul><h2><a class="nav-anchor" id="Getting-Started-1" href="#Getting-Started-1">Getting Started</a></h2><p>CSV.jl provides a number of utilities for working with delimited files. <code>CSV.File</code> provides a way to read files into columns of data, detecting column types. <code>CSV.Rows</code> provides a row iterator for looping over rows in a file. Inputs to either should be filenames as <code>String</code>s, or byte vectors (<code>AbstractVector{UInt8}</code>). To read other <code>IO</code> inputs, just call <code>read(io)</code> and pass the bytes directly to <code>CSV.File</code> or <code>CSV.Rows</code>.</p><h2><a class="nav-anchor" id="Key-Functions-1" href="#Key-Functions-1">Key Functions</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.File" href="#CSV.File"><code>CSV.File</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">CSV.File(source; kwargs...) =&gt; CSV.File</code></pre><p>Read a UTF-8 CSV input and return a <code>CSV.File</code> object.</p><p>The <code>source</code> argument can be one of:</p><ul><li>filename given as a string or FilePaths.jl type</li><li>an <code>AbstractVector{UInt8}</code> like a byte buffer or <code>codeunits(string)</code></li><li>an <code>IOBuffer</code></li></ul><p>To read a csv file from a url, use the HTTP.jl package, where the <code>HTTP.Response</code> body can be passed like:</p><pre><code class="language-julia">f = CSV.File(HTTP.get(url).body)</code></pre><p>For other <code>IO</code> or <code>Cmd</code> inputs, you can pass them like: <code>f = CSV.File(read(obj))</code>.</p><p>Opens the file and uses passed arguments to detect the number of columns and column types, unless column types are provided manually via the <code>types</code> keyword argument. Note that passing column types manually can slightly increase performance for each column type provided (column types can be given as a <code>Vector</code> for all columns, or specified per column via name or index in a <code>Dict</code>).</p><p>For text encodings other than UTF-8, load the <a href="https://github.com/JuliaStrings/StringEncodings.jl">StringEncodings.jl</a> package and call e.g. <code>CSV.File(open(read, source, enc&quot;ISO-8859-1&quot;))</code>.</p><p>The returned <code>CSV.File</code> object supports the <a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface and can iterate <code>CSV.Row</code>s. <code>CSV.Row</code> supports <code>propertynames</code> and <code>getproperty</code> to access individual row values. <code>CSV.File</code> also supports entire column access like a <code>DataFrame</code> via direct property access on the file object, like <code>f = CSV.File(file); f.col1</code>. Note that duplicate column names will be detected and adjusted to ensure uniqueness (duplicate column name <code>a</code> will become <code>a_1</code>). For example, one could iterate over a csv file with column names <code>a</code>, <code>b</code>, and <code>c</code> by doing:</p><pre><code class="language-julia">for row in CSV.File(file)
    println(&quot;a=$(row.a), b=$(row.b), c=$(row.c)&quot;)
end</code></pre><p>By supporting the Tables.jl interface, a <code>CSV.File</code> can also be a table input to any other table sink function. Like:</p><pre><code class="language-julia"># materialize a csv file as a DataFrame, without copying columns from CSV.File
df = CSV.File(file) |&gt; DataFrame

# load a csv file directly into an sqlite database table
db = SQLite.DB()
tbl = CSV.File(file) |&gt; SQLite.load!(db, &quot;sqlite_table&quot;)</code></pre><p>Supported keyword arguments include:</p><ul><li>File layout options:<ul><li><code>header=1</code>: the <code>header</code> argument can be an <code>Int</code>, indicating the row to parse for column names; or a <code>Range</code>, indicating a span of rows to be concatenated together as column names; or an entire <code>Vector{Symbol}</code> or <code>Vector{String}</code> to use as column names; if a file doesn&#39;t have column names, either provide them as a <code>Vector</code>, or set <code>header=0</code> or <code>header=false</code> and column names will be auto-generated (<code>Column1</code>, <code>Column2</code>, etc.)</li><li><code>normalizenames=false</code>: whether column names should be &quot;normalized&quot; into valid Julia identifier symbols; useful when iterating rows and accessing column values of a row via <code>getproperty</code> (e.g. <code>row.col1</code>)</li><li><code>datarow</code>: an <code>Int</code> argument to specify the row where the data starts in the csv file; by default, the next row after the <code>header</code> row is used. If <code>header=0</code>, then the 1st row is assumed to be the start of data; providing a <code>datarow</code> or <code>skipto</code> argument does <em>not</em> affect the <code>header</code> argument</li><li><code>skipto::Int</code>: identical to <code>datarow</code>, specifies the number of rows to skip before starting to read data</li><li><code>footerskip::Int</code>: number of rows at the end of a file to skip parsing</li><li><code>limit</code>: an <code>Int</code> to indicate a limited number of rows to parse in a csv file; use in combination with <code>skipto</code> to read a specific, contiguous chunk within a file; note for large files when multiple threads are used for parsing, the <code>limit</code> argument may not result in exact an exact # of rows parsed; use <code>threaded=false</code> to ensure an exact limit if necessary</li><li><code>transpose::Bool</code>: read a csv file &quot;transposed&quot;, i.e. each column is parsed as a row</li><li><code>comment</code>: rows that begin with this <code>String</code> will be skipped while parsing</li><li><code>ignoreemptylines::Bool=false</code>: whether empty rows/lines in a file should be ignored (if <code>false</code>, each column will be assigned <code>missing</code> for that empty row)</li><li><code>threaded::Bool</code>: whether parsing should utilize multiple threads; by default threads are used on large enough files, but isn&#39;t allowed when <code>transpose=true</code>; only available in Julia 1.3+</li><li><code>tasks::Integer=Threads.nthreads()</code>: for multithreaded parsing, this controls the number of tasks spawned to read a file in chunks concurrently; defaults to the # of threads Julia was started with (i.e. <code>JULIA_NUM_THREADS</code> environment variable)</li><li><code>select</code>: an <code>AbstractVector</code> of <code>Int</code>, <code>Symbol</code>, <code>String</code>, or <code>Bool</code>, or a &quot;selector&quot; function of the form <code>(i, name) -&gt; keep::Bool</code>; only columns in the collection or for which the selector function returns <code>true</code> will be parsed and accessible in the resulting <code>CSV.File</code>. Invalid values in <code>select</code> are ignored.</li><li><code>drop</code>: inverse of <code>select</code>; an <code>AbstractVector</code> of <code>Int</code>, <code>Symbol</code>, <code>String</code>, or <code>Bool</code>, or a &quot;drop&quot; function of the form <code>(i, name) -&gt; drop::Bool</code>; columns in the collection or for which the drop function returns <code>true</code> will ignored in the resulting <code>CSV.File</code>. Invalid values in <code>drop</code> are ignored.</li></ul></li><li>Parsing options:<ul><li><code>missingstrings</code>, <code>missingstring</code>: either a <code>String</code>, or <code>Vector{String}</code> to use as sentinel values that will be parsed as <code>missing</code>; by default, only an empty field (two consecutive delimiters) is considered <code>missing</code></li><li><code>delim=&#39;,&#39;</code>: a <code>Char</code> or <code>String</code> that indicates how columns are delimited in a file; if no argument is provided, parsing will try to detect the most consistent delimiter on the first 10 rows of the file</li><li><code>ignorerepeated::Bool=false</code>: whether repeated (consecutive) delimiters should be ignored while parsing; useful for fixed-width files with delimiter padding between cells</li><li><code>quotechar=&#39;&quot;&#39;</code>, <code>openquotechar</code>, <code>closequotechar</code>: a <code>Char</code> (or different start and end characters) that indicate a quoted field which may contain textual delimiters or newline characters</li><li><code>escapechar=&#39;&quot;&#39;</code>: the <code>Char</code> used to escape quote characters in a quoted field</li><li><code>dateformat::Union{String, Dates.DateFormat, Nothing}</code>: a date format string to indicate how Date/DateTime columns are formatted for the entire file</li><li><code>dateformats::Union{AbstractDict, Nothing}</code>: a Dict of date format strings to indicate how the Date/DateTime columns corresponding to the keys are formatted. The Dict can map column index <code>Int</code>, or name <code>Symbol</code> or <code>String</code> to the format string for that column.</li><li><code>decimal=&#39;.&#39;</code>: a <code>Char</code> indicating how decimals are separated in floats, i.e. <code>3.14</code> used &#39;.&#39;, or <code>3,14</code> uses a comma &#39;,&#39;</li><li><code>truestrings</code>, <code>falsestrings</code>: <code>Vectors of Strings</code> that indicate how <code>true</code> or <code>false</code> values are represented; by default only <code>true</code> and <code>false</code> are treated as <code>Bool</code></li></ul></li><li>Column Type Options:<ul><li><code>type</code>: a single type to use for parsing an entire file; i.e. all columns will be treated as the same type; useful for matrix-like data files</li><li><code>types</code>: a Vector or Dict of types to be used for column types; a Dict can map column index <code>Int</code>, or name <code>Symbol</code> or <code>String</code> to type for a column, i.e. Dict(1=&gt;Float64) will set the first column as a Float64, Dict(:column1=&gt;Float64) will set the column named column1 to Float64 and, Dict(&quot;column1&quot;=&gt;Float64) will set the column1 to Float64; if a <code>Vector</code> if provided, it must match the # of columns provided or detected in <code>header</code></li><li><code>typemap::Dict{Type, Type}</code>: a mapping of a type that should be replaced in every instance with another type, i.e. <code>Dict(Float64=&gt;String)</code> would change every detected <code>Float64</code> column to be parsed as <code>String</code>; only &quot;standard&quot; types are allowed to be mapped to another type, i.e. <code>Int64</code>, <code>Float64</code>, <code>Date</code>, <code>DateTime</code>, <code>Time</code>, and <code>Bool</code>. If a column of one of those types is &quot;detected&quot;, it will be mapped to the specified type.</li><li><code>pool::Union{Bool, Float64}=0.1</code>: if <code>true</code>, <em>all</em> columns detected as <code>String</code> will be internally pooled; alternatively, the proportion of unique values below which <code>String</code> columns should be pooled (by default 0.1, meaning that if the # of unique strings in a column is under 10%, it will be pooled)</li><li><code>lazystrings::Bool=false</code>: avoid allocating full strings in string columns; returns a custom <code>LazyStringVector</code> array type that <em>does not</em> support mutable operations (e.g. <code>push!</code>, <code>append!</code>, or even <code>setindex!</code>). Calling <code>copy(x)</code> will materialize a full <code>Vector{String}</code>. Also note that each <code>LazyStringVector</code> holds a reference to the full input file buffer, so it won&#39;t be closed after parsing and trying to delete or modify the file may result in errors (particularly on windows) and generally has undefined behavior. Given these caveats, this setting can help avoid lots of string allocations in large files and lead to faster parsing times.</li><li><code>strict::Bool=false</code>: whether invalid values should throw a parsing error or be replaced with <code>missing</code></li><li><code>silencewarnings::Bool=false</code>: if <code>strict=false</code>, whether invalid value warnings should be silenced</li></ul></li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/83e3a08a845550cb2c9ae7ffcb268ca5711aa1c1/src/file.jl#L92-L173">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.Chunks" href="#CSV.Chunks"><code>CSV.Chunks</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">CSV.Chunks(source; tasks::Integer=Threads.nthreads(), kwargs...) =&gt; CSV.Chunks</code></pre><p>Returns a file &quot;chunk&quot; iterator. Accepts all the same inputs and keyword arguments as <a href="#CSV.File"><code>CSV.File</code></a>, see those docs for explanations of each keyword argument.</p><p>The <code>tasks</code> keyword argument specifies how many chunks a file should be split up into, defaulting to  the # of threads available to Julia (i.e. <code>JULIA_NUM_THREADS</code> environment variable) or 8 if Julia is run single-threaded.</p><p>Each iteration of <code>CSV.Chunks</code> produces the next chunk of a file as a <code>CSV.File</code>. While initial file metadata detection is done only once (to determine # of columns, column names, etc), each iteration does independent type inference on columns. This is significant as different chunks may end up with different column types than previous chunks as new values are encountered in the file. Note that, as with <code>CSV.File</code>, types may be passed manually via the <code>type</code> or <code>types</code> keyword arguments.</p><p>This functionality is new and thus considered experimental; please <a href="https://github.com/JuliaData/CSV.jl/issues/new">open an issue</a> if you run into any problems/bugs.</p></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/83e3a08a845550cb2c9ae7ffcb268ca5711aa1c1/src/chunks.jl#L10-L28">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.Rows" href="#CSV.Rows"><code>CSV.Rows</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">CSV.Rows(source; kwargs...) =&gt; CSV.Rows</code></pre><p>Read a csv input returning a <code>CSV.Rows</code> object.</p><p>The <code>source</code> argument can be one of:</p><ul><li>filename given as a string or FilePaths.jl type</li><li>an <code>AbstractVector{UInt8}</code> like a byte buffer or <code>codeunits(string)</code></li><li>an <code>IOBuffer</code></li></ul><p>To read a csv file from a url, use the HTTP.jl package, where the <code>HTTP.Response</code> body can be passed like:</p><pre><code class="language-julia">f = CSV.Rows(HTTP.get(url).body)</code></pre><p>For other <code>IO</code> or <code>Cmd</code> inputs, you can pass them like: <code>f = CSV.Rows(read(obj))</code>.</p><p>While similar to <a href="#CSV.File"><code>CSV.File</code></a>, <code>CSV.Rows</code> provides a slightly different interface, the tradeoffs including:</p><ul><li>Very minimal memory footprint; while iterating, only the current row values are buffered</li><li>Only provides row access via iteration; to access columns, one can stream the rows into a table type</li><li>Performs no type inference; each column/cell is essentially treated as <code>Union{String, Missing}</code>, users can utilize the performant <code>Parsers.parse(T, str)</code> to convert values to a more specific type if needed, or pass types upon construction using the <code>type</code> or <code>types</code> keyword arguments</li></ul><p>Opens the file and uses passed arguments to detect the number of columns, ***but not*** column types (column types default to <code>String</code> unless otherwise manually provided). The returned <code>CSV.Rows</code> object supports the <a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface and can iterate rows. Each row object supports <code>propertynames</code>, <code>getproperty</code>, and <code>getindex</code> to access individual row values. Note that duplicate column names will be detected and adjusted to ensure uniqueness (duplicate column name <code>a</code> will become <code>a_1</code>). For example, one could iterate over a csv file with column names <code>a</code>, <code>b</code>, and <code>c</code> by doing:</p><pre><code class="language-julia">for row in CSV.Rows(file)
    println(&quot;a=$(row.a), b=$(row.b), c=$(row.c)&quot;)
end</code></pre><p>Supported keyword arguments include:</p><ul><li>File layout options:<ul><li><code>header=1</code>: the <code>header</code> argument can be an <code>Int</code>, indicating the row to parse for column names; or a <code>Range</code>, indicating a span of rows to be concatenated together as column names; or an entire <code>Vector{Symbol}</code> or <code>Vector{String}</code> to use as column names; if a file doesn&#39;t have column names, either provide them as a <code>Vector</code>, or set <code>header=0</code> or <code>header=false</code> and column names will be auto-generated (<code>Column1</code>, <code>Column2</code>, etc.)</li><li><code>normalizenames=false</code>: whether column names should be &quot;normalized&quot; into valid Julia identifier symbols; useful when iterating rows and accessing column values of a row via <code>getproperty</code> (e.g. <code>row.col1</code>)</li><li><code>datarow</code>: an <code>Int</code> argument to specify the row where the data starts in the csv file; by default, the next row after the <code>header</code> row is used. If <code>header=0</code>, then the 1st row is assumed to be the start of data</li><li><code>skipto::Int</code>: similar to <code>datarow</code>, specifies the number of rows to skip before starting to read data</li><li><code>limit</code>: an <code>Int</code> to indicate a limited number of rows to parse in a csv file; use in combination with <code>skipto</code> to read a specific, contiguous chunk within a file</li><li><code>transpose::Bool</code>: read a csv file &quot;transposed&quot;, i.e. each column is parsed as a row</li><li><code>comment</code>: rows that begin with this <code>String</code> will be skipped while parsing</li><li><code>ignoreemptylines::Bool=false</code>: whether empty rows/lines in a file should be ignored (if <code>false</code>, each column will be assigned <code>missing</code> for that empty row)</li></ul></li><li>Parsing options:<ul><li><code>missingstrings</code>, <code>missingstring</code>: either a <code>String</code>, or <code>Vector{String}</code> to use as sentinel values that will be parsed as <code>missing</code>; by default, only an empty field (two consecutive delimiters) is considered <code>missing</code></li><li><code>delim=&#39;,&#39;</code>: a <code>Char</code> or <code>String</code> that indicates how columns are delimited in a file; if no argument is provided, parsing will try to detect the most consistent delimiter on the first 10 rows of the file</li><li><code>ignorerepeated::Bool=false</code>: whether repeated (consecutive) delimiters should be ignored while parsing; useful for fixed-width files with delimiter padding between cells</li><li><code>quotechar=&#39;&quot;&#39;</code>, <code>openquotechar</code>, <code>closequotechar</code>: a <code>Char</code> (or different start and end characters) that indicate a quoted field which may contain textual delimiters or newline characters</li><li><code>escapechar=&#39;&quot;&#39;</code>: the <code>Char</code> used to escape quote characters in a quoted field</li><li><code>dateformat::Union{String, Dates.DateFormat, Nothing}</code>: a date format string to indicate how Date/DateTime columns are formatted for the entire file</li><li><code>decimal=&#39;.&#39;</code>: a <code>Char</code> indicating how decimals are separated in floats, i.e. <code>3.14</code> used &#39;.&#39;, or <code>3,14</code> uses a comma &#39;,&#39;</li><li><code>truestrings</code>, <code>falsestrings</code>: <code>Vectors of Strings</code> that indicate how <code>true</code> or <code>false</code> values are represented; by default only <code>true</code> and <code>false</code> are treated as <code>Bool</code></li></ul></li><li>Column Type Options:<ul><li><code>type</code>: a single type to use for parsing an entire file; i.e. all columns will be treated as the same type; useful for matrix-like data files</li><li><code>types</code>: a Vector or Dict of types to be used for column types; a Dict can map column index <code>Int</code>, or name <code>Symbol</code> or <code>String</code> to type for a column, i.e. Dict(1=&gt;Float64) will set the first column as a Float64, Dict(:column1=&gt;Float64) will set the column named column1 to Float64 and, Dict(&quot;column1&quot;=&gt;Float64) will set the column1 to Float64; if a <code>Vector</code> if provided, it must match the # of columns provided or detected in <code>header</code></li><li><code>typemap::Dict{Type, Type}</code>: a mapping of a type that should be replaced in every instance with another type, i.e. <code>Dict(Float64=&gt;String)</code> would change every detected <code>Float64</code> column to be parsed as <code>String</code></li><li><code>lazystrings::Bool=true</code>: avoid allocating full strings while parsing; accessing a string column will materialize the full <code>String</code></li><li><code>strict::Bool=false</code>: whether invalid values should throw a parsing error or be replaced with <code>missing</code></li><li><code>silencewarnings::Bool=false</code>: if <code>strict=false</code>, whether invalid value warnings should be silenced</li></ul></li><li>Iteration options:<ul><li><code>reusebuffer=false</code>: while iterating, whether a single row buffer should be allocated and reused on each iteration; only use if each row will be iterated once and not re-used (e.g. it&#39;s not safe to use this option if doing <code>collect(CSV.Rows(file))</code> because only current iterated row is &quot;valid&quot;)</li></ul></li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/83e3a08a845550cb2c9ae7ffcb268ca5711aa1c1/src/rows.jl#L35-L97">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.write" href="#CSV.write"><code>CSV.write</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-julia">CSV.write(file, table; kwargs...) =&gt; file
table |&gt; CSV.write(file; kwargs...) =&gt; file</code></pre><p>Write a <a href="https://github.com/JuliaData/Tables.jl">Tables.jl interface input</a> to a csv file, given as an <code>IO</code> argument or <code>String</code>/FilePaths.jl type representing the file name to write to. Alternatively, <code>CSV.RowWriter</code> creates a row iterator, producing a csv-formatted string for each row in an input table.</p><p>Supported keyword arguments include:</p><ul><li><code>delim::Union{Char, String}=&#39;,&#39;</code>: a character or string to print out as the file&#39;s delimiter</li><li><code>quotechar::Char=&#39;&quot;&#39;</code>: ascii character to use for quoting text fields that may contain delimiters or newlines</li><li><code>openquotechar::Char</code>: instead of <code>quotechar</code>, use <code>openquotechar</code> and <code>closequotechar</code> to support different starting and ending quote characters</li><li><code>escapechar::Char=&#39;&quot;&#39;</code>: ascii character used to escape quote characters in a text field</li><li><code>missingstring::String=&quot;&quot;</code>: string to print for <code>missing</code> values</li><li><code>dateformat=Dates.default_format(T)</code>: the date format string to use for printing out <code>Date</code> &amp; <code>DateTime</code> columns</li><li><code>append=false</code>: whether to append writing to an existing file/IO, if <code>true</code>, it will not write column names by default</li><li><code>writeheader=!append</code>: whether to write an initial row of delimited column names, not written by default if appending</li><li><code>header</code>: pass a list of column names (Symbols or Strings) to use instead of the column names of the input table</li><li><code>newline=&#39;\n&#39;</code>: character or string to use to separate rows (lines in the csv file)</li><li><code>quotestrings=false</code>: whether to force all strings to be quoted or not</li><li><code>decimal=&#39;.&#39;</code>: character to use as the decimal point when writing floating point numbers</li><li><code>transform=(col,val)-&gt;val</code>: a function that is applied to every cell e.g. we can transform all <code>nothing</code> values to <code>missing</code> using <code>(col, val) -&gt; something(val, missing)</code></li><li><code>bom=false</code>: whether to write a UTF-8 BOM header (0xEF 0xBB 0xBF) or not</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/83e3a08a845550cb2c9ae7ffcb268ca5711aa1c1/src/write.jl#L1-L23">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="CSV.RowWriter" href="#CSV.RowWriter"><code>CSV.RowWriter</code></a> — <span class="docstring-category">Type</span>.</div><div><div><pre><code class="language-julia">CSV.RowWriter(table; kwargs...)</code></pre><p>Creates an iterator that produces csv-formatted strings for each row in the input table.</p><p>Supported keyword arguments include:</p><ul><li><code>bufsize::Int=2^22</code>: The length of the buffer to use when writing each csv-formatted row; default 4MB; if a row is larger than the <code>bufsize</code> an error is thrown</li><li><code>delim::Union{Char, String}=&#39;,&#39;</code>: a character or string to print out as the file&#39;s delimiter</li><li><code>quotechar::Char=&#39;&quot;&#39;</code>: ascii character to use for quoting text fields that may contain delimiters or newlines</li><li><code>openquotechar::Char</code>: instead of <code>quotechar</code>, use <code>openquotechar</code> and <code>closequotechar</code> to support different starting and ending quote characters</li><li><code>escapechar::Char=&#39;&quot;&#39;</code>: ascii character used to escape quote characters in a text field</li><li><code>missingstring::String=&quot;&quot;</code>: string to print for <code>missing</code> values</li><li><code>dateformat=Dates.default_format(T)</code>: the date format string to use for printing out <code>Date</code> &amp; <code>DateTime</code> columns</li><li><code>header</code>: pass a list of column names (Symbols or Strings) to use instead of the column names of the input table</li><li><code>newline=&#39;\n&#39;</code>: character or string to use to separate rows (lines in the csv file)</li><li><code>quotestrings=false</code>: whether to force all strings to be quoted or not</li><li><code>decimal=&#39;.&#39;</code>: character to use as the decimal point when writing floating point numbers</li><li><code>transform=(col,val)-&gt;val</code>: a function that is applied to every cell e.g. we can transform all <code>nothing</code> values to <code>missing</code> using <code>(col, val) -&gt; something(val, missing)</code></li><li><code>bom=false</code>: whether to write a UTF-8 BOM header (0xEF 0xBB 0xBF) or not</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/JuliaData/CSV.jl/blob/83e3a08a845550cb2c9ae7ffcb268ca5711aa1c1/src/write.jl#L45-L64">source</a></section><h2><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h2><h3><a class="nav-anchor" id="Basic-1" href="#Basic-1">Basic</a></h3><h4><a class="nav-anchor" id="File-1" href="#File-1">File</a></h4><pre><code class="language-none">col1,col2,col3,col4,col5,col6,col7,col8
,1,1.0,1,one,2019-01-01,2019-01-01T00:00:00,true
,2,2.0,2,two,2019-01-02,2019-01-02T00:00:00,false
,3,3.0,3.14,three,2019-01-03,2019-01-03T00:00:00,true</code></pre><h4><a class="nav-anchor" id="Syntax-1" href="#Syntax-1">Syntax</a></h4><pre><code class="language-julia">CSV.File(file)</code></pre><p>By default, <code>CSV.File</code> will automatically detect this file&#39;s delimiter <code>&#39;,&#39;</code>, and the type of each column. By default, it treats &quot;empty fields&quot; as <code>missing</code> (the entire first column in this example). It also automatically handles promoting types, like the 4th column, where the first two values are <code>Int</code>, but the 3rd row has a <code>Float64</code> value (<code>3.14</code>). The resulting column&#39;s type will be <code>Float64</code>. Parsing can detect <code>Int64</code>, <code>Float64</code>, <code>Date</code>, <code>DateTime</code>, <code>Time</code> and <code>Bool</code> types, with <code>String</code> as the fallback type for any column.</p><h3><a class="nav-anchor" id="Auto-Delimiter-Detection-1" href="#Auto-Delimiter-Detection-1">Auto-Delimiter Detection</a></h3><h4><a class="nav-anchor" id="File-2" href="#File-2">File</a></h4><pre><code class="language-none">col1|col2
1|2
3|4</code></pre><h4><a class="nav-anchor" id="Syntax-2" href="#Syntax-2">Syntax</a></h4><pre><code class="language-julia">CSV.File(file)</code></pre><p>By default, <code>CSV.File</code> will try to detect a file&#39;s delimiter from the first 10 lines of the file; candidate delimiters include <code>&#39;,&#39;</code>, <code>&#39;\t&#39;</code>, <code>&#39; &#39;</code>, <code>&#39;|&#39;</code>, <code>&#39;;&#39;</code>, and <code>&#39;:&#39;</code>. If it can&#39;t auto-detect the delimiter, it will assume <code>&#39;,&#39;</code>. If your file includes a different character or string delimiter, just pass <code>delim=X</code> where <code>X</code> is the character or string. For this file you could also do <code>CSV.File(file; delim=&#39;|&#39;)</code>.</p><h3><a class="nav-anchor" id="String-Delimiter-1" href="#String-Delimiter-1">String Delimiter</a></h3><h4><a class="nav-anchor" id="File-3" href="#File-3">File</a></h4><pre><code class="language-none">col1::col2
1::2
3::4</code></pre><h4><a class="nav-anchor" id="Syntax-3" href="#Syntax-3">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; delim=&quot;::&quot;)</code></pre><p>In this example, our file has fields separated by the string <code>&quot;::&quot;</code>; we can pass this as the <code>delim</code> keyword argument.</p><h3><a class="nav-anchor" id="No-Header-1" href="#No-Header-1">No Header</a></h3><h4><a class="nav-anchor" id="File-4" href="#File-4">File</a></h4><pre><code class="language-none">1,2,3
4,5,6
7,8,9</code></pre><h4><a class="nav-anchor" id="Syntax-4" href="#Syntax-4">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; header=false)
CSV.File(file; header=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;])
CSV.File(file; header=[:col1, :col2, :col3])</code></pre><p>In this file, there is no header row that contains column names. In the first option, we pass <code>header=false</code>, and column names will be generated like <code>[:Column1, :Column2, :Column3]</code>. In the two latter examples, we pass our own explicit column names, either as <code>String</code>s or <code>Symbol</code>s.</p><h3><a class="nav-anchor" id="Normalize-Column-Names-1" href="#Normalize-Column-Names-1">Normalize Column Names</a></h3><h4><a class="nav-anchor" id="File-5" href="#File-5">File</a></h4><pre><code class="language-none">column one,column two, column three
1,2,3
4,5,6</code></pre><h4><a class="nav-anchor" id="Syntax-5" href="#Syntax-5">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; normalizenames=true)</code></pre><p>In this file, our column names have spaces in them. It can be convenient with a <code>CSV.File</code> or <code>DataFrame</code> to access entire columns via property access, e.g. if <code>f = CSV.File(file)</code> with column names like <code>[:col1, :col2]</code>, I can access the entire first column of the file like <code>f.col1</code>, or for the second, <code>f.col2</code>. The call of <code>f.col1</code> actually gets rewritten to the function call <code>getproperty(f, :col1)</code>, which is the function implemented in CSV.jl that returns the <code>col1</code> column from the file. When a column name is not a single atom Julia identifier, this is inconvient, because <code>f.column one</code> is not valid, so I would have to manually call <code>getproperty(f, Symbol(&quot;column one&quot;)</code>. <code>normalizenames=true</code> comes to our rescue; it will replace invalid identifier characters with underscores to ensure each column is a valid Julia identifier, so for this file, we would end up with column names like <code>[:column_one, :column_two]</code>. You can call <code>propertynames(f)</code> on any <code>CSV.File</code> to see the parsed column names.</p><h3><a class="nav-anchor" id="Datarow-1" href="#Datarow-1">Datarow</a></h3><h4><a class="nav-anchor" id="File-6" href="#File-6">File</a></h4><pre><code class="language-none">col1,col2,col3
metadata1,metadata2,metadata3
extra1,extra2,extra3
1,2,3
4,5,6
7,8,9</code></pre><h4><a class="nav-anchor" id="Syntax-6" href="#Syntax-6">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; datarow=4)
CSV.File(file; skipto=4)</code></pre><p>This file has extra rows in between our header row <code>col1,col2,col3</code> and the start of our data <code>1,2,3</code> on row 4. We can use the <code>datarow</code> or <code>skipto</code> keyword arguments to provide a row number where the &quot;data&quot; of our file begins.</p><h3><a class="nav-anchor" id="Reading-Chunks-1" href="#Reading-Chunks-1">Reading Chunks</a></h3><h4><a class="nav-anchor" id="File-7" href="#File-7">File</a></h4><pre><code class="language-none">col1,col2,col3
1,2,3
4,5,6
7,8,9
10,11,12
13,14,15
16,17,18
19,20,21</code></pre><h4><a class="nav-anchor" id="Syntax-7" href="#Syntax-7">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; limit=3)
CSV.File(file; skipto=4, limit=1)
CSV.File(file; skipto=7, footerskip=1)</code></pre><p>In this example, we desire to only read a subset of rows from the file. Using the <code>limit</code>, <code>skipto</code>, and <code>footerskip</code> keyword arguments, we can specify the exact rows we wish to parse.</p><h3><a class="nav-anchor" id="Transposed-Data-1" href="#Transposed-Data-1">Transposed Data</a></h3><h4><a class="nav-anchor" id="File-8" href="#File-8">File</a></h4><pre><code class="language-none">col1,1,2,3
col2,4,5,6
col3,7,8,9</code></pre><h4><a class="nav-anchor" id="Syntax-8" href="#Syntax-8">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; transpose=true)</code></pre><p>This file has the column names in the first column, and data that extends alongs rows horizontally. The data for <code>col1</code> is all on the first row, similarly for <code>col2</code> and its data on row 2. In this case, we wish to read the file &quot;transposed&quot;, or treating rows as columns. By passing <code>transpose=true</code>, CSV.jl will read column names from the first column, and the data for each column from its corresponding row.</p><h3><a class="nav-anchor" id="Commented-Rows-1" href="#Commented-Rows-1">Commented Rows</a></h3><h4><a class="nav-anchor" id="File-9" href="#File-9">File</a></h4><pre><code class="language-none">col1,col2,col3
# this row is commented and we&#39;d like to ignore it while parsing
1,2,3
4,5,6</code></pre><h4><a class="nav-anchor" id="Syntax-9" href="#Syntax-9">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; comment=&quot;#&quot;)
CSV.File(file; datarow=3)</code></pre><p>This file has some rows that begin with the <code>&quot;#&quot;</code> string and denote breaks in the data for commentary. We wish to ignore these rows for purposes of reading data. We can pass <code>comment=&quot;#&quot;</code> and parsing will ignore any row that begins with this string. Alternatively, we can pass <code>datarow=3</code> for this example specifically since there is only the one row to skip.</p><h3><a class="nav-anchor" id="Missing-Strings-1" href="#Missing-Strings-1">Missing Strings</a></h3><h4><a class="nav-anchor" id="File-10" href="#File-10">File</a></h4><pre><code class="language-none">code,age,score
0,21,3.42
1,42,6.55
-999,81,NA
-999,83,NA</code></pre><h4><a class="nav-anchor" id="Syntax-10" href="#Syntax-10">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; missingstring=&quot;-999&quot;)
CSV.File(file; missingstrings=[&quot;-999&quot;, &quot;NA&quot;])</code></pre><p>In this file, our <code>code</code> column has two expected codes, <code>0</code> and <code>1</code>, but also a few &quot;invalid&quot; codes, which are input as <code>-999</code>. We&#39;d like to read the column as <code>Int64</code>, but treat the <code>-999</code> values as &quot;missing&quot; values. By passing <code>missingstring=&quot;-999&quot;</code>, we signal that this value should be replaced with the literal <code>missing</code> value builtin to the Julia language. We can then do things like <code>dropmissing(f.col1)</code> to ignore those values, for example. In the second recommended syntax, we also want to treat the <code>NA</code> values in our <code>score</code> column as <code>missing</code>, so we pass both strings like <code>missingstrings=[&quot;-999&quot;, &quot;NA&quot;]</code>.</p><h3><a class="nav-anchor" id="Fixed-Width-Files-1" href="#Fixed-Width-Files-1">Fixed Width Files</a></h3><h4><a class="nav-anchor" id="File-11" href="#File-11">File</a></h4><pre><code class="language-none">col1    col2 col3
123431  2    3421
2355    346  7543</code></pre><h4><a class="nav-anchor" id="Syntax-11" href="#Syntax-11">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; delim=&#39; &#39;, ignorerepeated=true)</code></pre><p>This is an example of a &quot;fixed width&quot; file, where each column is the same number of characters away from each other on each row. This is different from a normal delimited file where each occurence of a delimiter indicates a separate field. With fixed width, however, fields are &quot;padded&quot; with extra delimiters (in this case <code>&#39; &#39;</code>) so that each column is the same number of characters each time. In addition to our <code>delim</code>, we can pass <code>ignorerepeated=true</code>, which tells parsing that consecutive delimiters should be treated as a single delimiter.</p><h3><a class="nav-anchor" id="Quoted-and-Escaped-Fields-1" href="#Quoted-and-Escaped-Fields-1">Quoted &amp; Escaped Fields</a></h3><h4><a class="nav-anchor" id="File-12" href="#File-12">File</a></h4><pre><code class="language-none">col1,col2
&quot;quoted field with a delimiter , inside&quot;,&quot;quoted field that contains a \\n newline and &quot;&quot;inner quotes&quot;&quot;&quot;
unquoted field,unquoted field with &quot;inner quotes&quot;</code></pre><h4><a class="nav-anchor" id="Syntax-12" href="#Syntax-12">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; quotechar=&#39;&quot;&#39;, escapechar=&#39;&quot;&#39;)
CSV.File(file; openquotechar=&#39;&quot;&#39;, closequotechar=&#39;&quot;&#39;, escapechar=&#39;&quot;&#39;)</code></pre><p>In this file, we have a few &quot;quoted&quot; fields, which means the field&#39;s value starts and ends with <code>quotechar</code> (or <code>openquotechar</code> and <code>closequotechar</code>, respectively). Quoted fields allow the field to contain characters that would otherwise be significant to parsing, such as delimiters or newline characters. When quoted, parsing will ignore these otherwise signficant characters until the closing quote character is found. For quoted fields that need to also include the quote character itself, an escape character is provided to tell parsing to ignore the next character when looking for a close quote character. In the syntax examples, the keyword arguments are passed explicitly, but these also happen to be the default values, so just doing <code>CSV.File(file)</code> would result in successful parsing.</p><h3><a class="nav-anchor" id="DateFormat-1" href="#DateFormat-1">DateFormat</a></h3><h4><a class="nav-anchor" id="File-13" href="#File-13">File</a></h4><pre><code class="language-none">code,date
0,2019/01/01
1,2019/01/02</code></pre><h4><a class="nav-anchor" id="Syntax-13" href="#Syntax-13">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; dateformat=&quot;yyyy/mm/dd&quot;)</code></pre><p>In this file, our <code>date</code> column has dates that are formatted like <code>yyyy/mm/dd</code>. We can pass just such a string to the <code>dateformat</code> keyword argument to tell parsing to use it when looking for <code>Date</code> or <code>DateTime</code> columns. Note that currently, only a single <code>dateformat</code> string can be passed to parsing, meaning multiple columns with different date formats cannot all be parsed as <code>Date</code>/<code>DateTime</code>.</p><h3><a class="nav-anchor" id="Custom-Decimal-Separator-1" href="#Custom-Decimal-Separator-1">Custom Decimal Separator</a></h3><h4><a class="nav-anchor" id="File-14" href="#File-14">File</a></h4><pre><code class="language-none">col1;col2;col3
1,01;2,02;3,03
4,04;5,05;6,06</code></pre><h4><a class="nav-anchor" id="Syntax-14" href="#Syntax-14">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; delim=&#39;;&#39;, decimal=&#39;,&#39;)</code></pre><p>In many places in the world, floating point number decimals are separated with a comma instead of a period (<code>3,14</code> vs. <code>3.14</code>). We can correctly parse these numbers by passing in the <code>decimal=&#39;,&#39;</code> keyword argument. Note that we probably need to explicitly pass <code>delim=&#39;;&#39;</code> in this case, since the parser will probably think that it detected <code>&#39;,&#39;</code> as the delimiter.</p><h3><a class="nav-anchor" id="Custom-Bool-Strings-1" href="#Custom-Bool-Strings-1">Custom Bool Strings</a></h3><h4><a class="nav-anchor" id="File-15" href="#File-15">File</a></h4><pre><code class="language-none">id,paid,attended
0,T,TRUE
1,F,TRUE
2,T,FALSE
3,F,FALSE</code></pre><h4><a class="nav-anchor" id="Syntax-15" href="#Syntax-15">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; truestrings=[&quot;T&quot;, &quot;TRUE&quot;], falsestrings=[&quot;F&quot;, &quot;FALSE&quot;])</code></pre><p>By default, parsing only considers the string values <code>true</code> and <code>false</code> as valid <code>Bool</code> values. To consider alternative values, we can pass a <code>Vector{String}</code> to the <code>truestrings</code> and <code>falsestrings</code> keyword arguments.</p><h3><a class="nav-anchor" id="Matrix-like-Data-1" href="#Matrix-like-Data-1">Matrix-like Data</a></h3><h4><a class="nav-anchor" id="File-16" href="#File-16">File</a></h4><pre><code class="language-none">1.0 0.0 0.0
0.0 1.0 0.0
0.0 0.0 1.0</code></pre><h4><a class="nav-anchor" id="Syntax-16" href="#Syntax-16">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; header=false)
CSV.File(file; header=false, delim=&#39; &#39;, type=Float64)</code></pre><p>This file contains a 3x3 identity matrix of <code>Float64</code>. By default, parsing will detect the delimiter and type, but we can also explicitly pass <code>delim= &#39; &#39;</code> and <code>type=Float64</code>, which tells parsing to explicitly treat each column as <code>Float64</code>, without having to guess the type on its own.</p><h3><a class="nav-anchor" id="Providing-Types-1" href="#Providing-Types-1">Providing Types</a></h3><h4><a class="nav-anchor" id="File-17" href="#File-17">File</a></h4><pre><code class="language-none">col1,col2,col3
1,2,3
4,5,invalid
6,7,8</code></pre><h4><a class="nav-anchor" id="Syntax-17" href="#Syntax-17">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; types=Dict(3 =&gt; Int))
CSV.File(file; types=Dict(:col3 =&gt; Int))
CSV.File(file; types=Dict(&quot;col3&quot; =&gt; Int))
CSV.File(file; types=[Int, Int, Int])
CSV.File(file; types=[Int, Int, Int], silencewarnings=true)
CSV.File(file; types=[Int, Int, Int], strict=true)</code></pre><p>In this file, our 3rd column has an invalid value on the 2nd row <code>invalid</code>. Let&#39;s imagine we&#39;d still like to treat it as an <code>Int</code> column, and ignore the <code>invalid</code> value. The syntax examples provide several ways we can tell parsing to treat the 3rd column as <code>Int</code>, by referring to column index <code>3</code>, or column name with <code>Symbol</code> or <code>String</code>. We can also provide an entire <code>Vector</code> of types for each column (and which needs to match the length of columns in the file). There are two additional keyword arguments that control parsing behavior; in the first 4 syntax examples, we would see a warning printed like <code>&quot;warning: invalid Int64 value on row 2, column 3&quot;</code>. In the fifth example, passing <code>silencewarnings=true</code> will suppress this warning printing. In the last syntax example, passing <code>strict=true</code> will result in an error being thrown during parsing.</p><h3><a class="nav-anchor" id="Typemap-1" href="#Typemap-1">Typemap</a></h3><h4><a class="nav-anchor" id="File-18" href="#File-18">File</a></h4><pre><code class="language-none">zipcode,score
03494,9.9
12345,6.7
84044,3.4</code></pre><h4><a class="nav-anchor" id="Syntax-18" href="#Syntax-18">Syntax</a></h4><pre><code class="language-julia">CSV.File(file; typemap=Dict(Int =&gt; String))
CSV.File(file; types=Dict(:zipcode =&gt; String))</code></pre><p>In this file, we have U.S. zipcodes in the first column that we&#39;d rather not treat as <code>Int</code>, but parsing will detect it as such. In the first syntax example, we pass <code>typemap=Dict(Int =&gt; String)</code>, which tells parsing to treat any detected <code>Int</code> columns as <code>String</code> instead. In the second syntax example, we alternatively set the <code>zipcode</code> column type manually.</p><h3><a class="nav-anchor" id="Pooled-Values-1" href="#Pooled-Values-1">Pooled Values</a></h3><h4><a class="nav-anchor" id="File-19" href="#File-19">File</a></h4><pre><code class="language-none">id,code
A18E9,AT
BF392,GC
93EBC,AT
54EE1,AT
8CD2E,GC</code></pre><h4><a class="nav-anchor" id="Syntax-19" href="#Syntax-19">Syntax</a></h4><pre><code class="language-julia">CSV.File(file)
CSV.File(file; pool=0.4)
CSV.File(file; pool=0.6)</code></pre><p>In this file, we have an <code>id</code> column and a <code>code</code> column. There can be advantages with various DataFrame/table operations like joining and grouping when <code>String</code> values are &quot;pooled&quot;, meaning each unique value is mapped to a <code>UInt64</code>. By default, <code>pool=0.1</code>, so string columns with low cardinality are pooled by default. Via the <code>pool</code> keyword argument, we can provide greater control: <code>pool=0.4</code> means that if 40% or less of a column&#39;s values are unique, then it will be pooled.</p><h3><a class="nav-anchor" id="Select/Drop-Columns-From-File-1" href="#Select/Drop-Columns-From-File-1">Select/Drop Columns From File</a></h3><h4><a class="nav-anchor" id="File-20" href="#File-20">File</a></h4><pre><code class="language-none">a,b,c
1,2,3
4,5,6
7,8,9</code></pre><h4><a class="nav-anchor" id="Syntax-20" href="#Syntax-20">Syntax</a></h4><pre><code class="language-julia"># select
CSV.File(file; select=[1, 3])
CSV.File(file; select=[:a, :c])
CSV.File(file; select=[&quot;a&quot;, &quot;c&quot;])
CSV.File(file; select=[true, false, true])
CSV.File(file; select=(i, nm) -&gt; i in (1, 3))
# drop
CSV.File(file; drop=[2])
CSV.File(file; drop=[:b])
CSV.File(file; drop=[&quot;b&quot;])
CSV.File(file; drop=[false, true, false])
CSV.File(file; drop=(i, nm) -&gt; i == 2)</code></pre><p>For this file, we have columns <code>a</code>, <code>b</code>, and <code>c</code>; we might only be interested in the data in columns <code>a</code> and <code>c</code>. Using the <code>select</code> or <code>drop</code> keyword arguments can allow efficiently choosing of columns from a file; columns not selected or dropped will be efficiently skipped while parsing, allowing for performance boosts. The arguments to <code>select</code> or <code>drop</code> can be one of: <code>AbstractVector{Int}</code> a collection of column indices; <code>AbstractVector{Symbol}</code> or <code>AbstractVector{String}</code> a collection of column names as <code>Symbol</code> or <code>String</code>; <code>AbstractVector{Bool}</code> a collection of <code>Bool</code> equal in length to the # of columns signaling whether a column should be selected or dropped; or a selector/drop function of the form <code>(i, name) -&gt; keep_or_drop::Bool</code>, i.e. it takes a column index <code>i</code> and column name <code>name</code> and returns a <code>Bool</code> signaling whether a column should be selected or dropped.</p><h3><a class="nav-anchor" id="Non-UTF-8-character-encodings-1" href="#Non-UTF-8-character-encodings-1">Non-UTF-8 character encodings</a></h3><p>Like Julia in general, CSV.jl interprets strings as being encoded in UTF-8. The <a href="https://github.com/JuliaStrings/StringEncodings.jl">StringEncodings</a> package has to be used to read or write CSV files in other character encodings.</p><h4><a class="nav-anchor" id="Example:-writing-to-and-reading-from-a-file-encoded-in-ISO-8859-1-1" href="#Example:-writing-to-and-reading-from-a-file-encoded-in-ISO-8859-1-1">Example: writing to and reading from a file encoded in ISO-8859-1</a></h4><pre><code class="language-julia">using CSV, DataFrames, StringEncodings

# writing to ISO-8859-1 file
a = DataFrame(a = [&quot;café&quot;, &quot;noël&quot;])
open(&quot;a.csv&quot;, enc&quot;ISO-8859-1&quot;, &quot;w&quot;) do io
    CSV.write(io, a)
end

# reading from ISO-8859-1 file
CSV.File(open(read, &quot;a.csv&quot;, enc&quot;ISO-8859-1&quot;)) |&gt; DataFrame

# alternative: reencode data to UTF-8 in a new file and read from it
open(&quot;a2.csv&quot;, &quot;w&quot;) do io
    foreach(x -&gt; println(io, x), eachline(&quot;a.csv&quot;, enc&quot;ISO-8859-1&quot;))
end
CSV.File(&quot;a2.csv&quot;) |&gt; DataFrame</code></pre><p>Reencoding to a new file as in the last example above avoids storing an additional copy of the data in memory, which may be useful for large files that do not fit in RAM.</p><h3><a class="nav-anchor" id="Reading-CSV-from-gzip-(.gz)-and-zip-files-1" href="#Reading-CSV-from-gzip-(.gz)-and-zip-files-1">Reading CSV from gzip (.gz) and zip files</a></h3><h4><a class="nav-anchor" id="Example:-reading-from-a-gzip-(.gz)-file-1" href="#Example:-reading-from-a-gzip-(.gz)-file-1">Example: reading from a gzip (.gz) file</a></h4><pre><code class="language-julia">using CSV, DataFrames, CodecZlib, Mmap
a = DataFrame(a = 1:3)
CSV.write(&quot;a.csv&quot;, a)

# Windows users who do not have gzip available on the PATH should manually gzip the CSV
;gzip a.csv

a_copy = CSV.File(transcode(GzipDecompressor, Mmap.mmap(&quot;a.csv.gz&quot;))) |&gt; DataFrame

a == a_copy # true; restored successfully
</code></pre><h4><a class="nav-anchor" id="Example:-reading-from-a-zip-file-1" href="#Example:-reading-from-a-zip-file-1">Example: reading from a zip file</a></h4><pre><code class="language-julia">using ZipFile, CSV, DataFrames

a = DataFrame(a = 1:3)
CSV.write(&quot;a.csv&quot;, a)

# zip the file; Windows users who do not have zip available on the PATH can manually zip the CSV
# or write directly into the zip archive as shown below
;zip a.zip a.csv

# alternatively, write directly into the zip archive (without creating an unzipped csv file first)
z = ZipFile.Writer(&quot;a2.zip&quot;)
f = ZipFile.addfile(z, &quot;a.csv&quot;, method=ZipFile.Deflate)
a |&gt; CSV.write(f)
close(z)

# read file from zip archive
z = ZipFile.Reader(&quot;a.zip&quot;) # or &quot;a2.zip&quot;

# identify the right file in zip
a_file_in_zip = filter(x-&gt;x.name == &quot;a.csv&quot;, z.files)[1]

a_copy = CSV.File(a_file_in_zip) |&gt; DataFrame

a == a_copy</code></pre><footer><hr/></footer></article></body></html>
